#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
@author = 'wyx'
@time = 2017/6/4 12:28
@annotation = ''
"""
"""
线性 
特征组合 
神经网络 非线性转换层（激活函数）连接隐藏层

反向传播——>递归下降


逻辑回归解决二元
请查看以下 Softmax 变体：

    完整Softmax 
        是我们一直以来讨论的 Softmax；也就是说，Softmax 针对每个可能的类别计算概率。
    候选采样指 
        Softmax 针对所有正类别标签计算概率，但仅针对负类别标签的随机样本计算概率。例如，如果我们想要确定某个输入图片是小猎犬还是寻血猎犬图片，则不必针对每个非狗狗样本提供概率。
    
类别数量较少时，完整 Softmax 代价很小，但随着类别数量的增加，它的代价会变得极其高昂。候选采样可以提高处理具有大量类别的问题的效率。


Softmax 假设每个样本只是一个类别的成员，一些样本可以同时是多个类别的成员。对于此类示例：
您不能使用 Softmax。
您必须依赖多个逻辑回归。
"""
